{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9VMJhK0AdvQfDOnHl7qA7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupj/fine-tuning-llama/blob/main/finetune_llama_3_together_ai_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning and Inference using Low-Rank Adaptations(LoRA)\n"
      ],
      "metadata": {
        "id": "uBzWuRr-4ram"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook I will:\n",
        "\n",
        "- perform LoRA fine-tuning on Together AI\n",
        "- perform LoRA inference on the trained model\n",
        "- swap and perform inference using various LoRA fine-tunes!"
      ],
      "metadata": {
        "id": "LMDSY8354x6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU together\n",
        "os.environ[\"UV_SYSTEM_PYTHON\"] = \"1\"\n",
        "!pip install uv"
      ],
      "metadata": {
        "id": "XXsXr4a94xga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2b3a9a-340d-40d7-db2a-9c57d6f8db78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uv\n",
            "  Downloading uv-0.6.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.6.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from together import Together\n",
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ['TOGETHER_API_KEY'] = userdata.get('TOGETHER_API_KEY')\n",
        "    os.environ['WANDB_API_KEY'] = userdata.get('WANDB_API_KEY')\n",
        "except ImportError:\n",
        "    print(\"Not in Google Colab environment\")\n",
        "\n",
        "for key in ['TOGETHER_API_KEY', 'WANDB_API_KEY']:\n",
        "    try:\n",
        "        api_key = os.environ[key]\n",
        "        if not api_key:\n",
        "            raise ValueError(f\"{key} environment variable is empty\")\n",
        "    except KeyError:\n",
        "        api_key = input(f\"{key} environment variable is not set. Please enter your API key: \")\n",
        "        os.environ[key] = api_key\n",
        "\n",
        "client = Together(api_key = TOGETHER_API_KEY)\n"
      ],
      "metadata": {
        "id": "9Bs0zPUs4xeN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform LoRA Fine-tune"
      ],
      "metadata": {
        "id": "S3fS2Pj5WyFV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "__WnBVU74iR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58522291-5386-4f60-a6bd-799a9fd2bd67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Uploading file small_coqa_10.jsonl: 100%|██████████| 33.4k/33.4k [00:00<00:00, 63.2kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file-cc6d531d-190b-4d3d-a26f-94193aa9362e\n"
          ]
        }
      ],
      "source": [
        "# Upload dataset to Together AI\n",
        "\n",
        "train_file_resp = client.files.upload(\"datasets/small_coqa_10.jsonl\", check=True)\n",
        "\n",
        "print(train_file_resp.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's fine tune `Llama-3.2-1B-Instruct` model**"
      ],
      "metadata": {
        "id": "S5E5_vL6Y2oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_resp = client.fine_tuning.create(\n",
        "    training_file   = train_file_resp.id,\n",
        "    model           = 'meta-llama/Llama-3.2-1B-Instruct',\n",
        "    train_on_inputs = \"auto\",\n",
        "    n_epochs        = 3,\n",
        "    n_checkpoints   = 1,\n",
        "    wandb_api_key   = WANDB_API_KEY,\n",
        "    lora            = True,\n",
        "    warmup_ratio    = 0,\n",
        "    learning_rate   = 1e-5,\n",
        "    suffix          = 'FT-webinar-demo-1b',\n",
        ")\n",
        "\n",
        "print(ft_resp.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql60jxzSXjN-",
        "outputId": "2b844793-6ae2-409f-d575-53b0ad25eb0d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ft-5bf7b814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft_resp.output_name)\n",
        "print(ft_resp.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNWcFMTeqHKD",
        "outputId": "b092add2-999b-4186-961c-4f8e890bdb8f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anupjadhav/Llama-3.2-1B-Instruct-FT-webinar-demo-1b-7967b7fd\n",
            "ft-5bf7b814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA Inference\n"
      ],
      "metadata": {
        "id": "6L0Aq7wVWfIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = ft_resp.output_name\n",
        "user_prompt = \"what did Venters call Lassiter?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model = model_name + '-adapter',\n",
        "  messages = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": user_prompt,\n",
        "      }\n",
        "  ],\n",
        "  max_tokens = 224,\n",
        "  temperature = 0.7,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_MS9xemq6vL",
        "outputId": "2d3cbc26-ff2f-4e75-836c-8bb80692c6c7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the movie 007 James Bond, Bond's partner is Lassiter and character 007 James Bond also has a nickname for Lassiter, which is 'The Ginger Nuts of Chemical Weapons'.\n"
          ]
        }
      ]
    }
  ]
}